{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c1b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.utils.data\n",
    "from torch.nn import DataParallel\n",
    "from datetime import datetime\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "#from config import BATCH_SIZE, PROPOSAL_NUM, SAVE_FREQ, LR, WD, resume, save_dir\n",
    "#from core import model, dataset\n",
    "#from core.utils import init_log, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcc53999",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "PROPOSAL_NUM = 6\n",
    "CAT_NUM = 4\n",
    "INPUT_SIZE = (224, 224)  # (w, h)\n",
    "LR = 0.001\n",
    "WD = 1e-4\n",
    "SAVE_FREQ = 1\n",
    "resume = ''\n",
    "test_model = 'model.ckpt'\n",
    "save_dir = '/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ed5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff72b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.load('x_train.npy')\n",
    "y_train=np.load('y_train.npy')\n",
    "x_valid=np.load('x_valid.npy')\n",
    "y_valid=np.load('y_valid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a89a6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = np.array(x_train, dtype='float32')\n",
    "#y_train = np.array(y_train, dtype='int64')\n",
    "#x_valid = np.array(x_valid, dtype='float32')\n",
    "#y_valid = np.array(y_valid, dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "203a6273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1140, 512, 512, 3), (1140, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87d4c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 불러올 때 사용할 변형(transformation) 객체 정의\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    #transforms.RandomHorizontalFlip(), # augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 정규화(normalization)\n",
    "])\n",
    "\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_dir = './data_10'\n",
    "train_datasets = datasets.ImageFolder(os.path.join(data_dir, 'Training'), transforms_train)\n",
    "test_datasets = datasets.ImageFolder(os.path.join(data_dir, 'Test'), transforms_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_datasets, batch_size=4, shuffle=True, num_workers=4)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007bd487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터셋 크기: 1140\n",
      "테스트 데이터셋 크기: 236\n",
      "클래스: ['30017_롯데밀키스250ML', '30033_코카콜라250ML', '40007_롯데마운틴듀250ML', '40036_오란씨깔라만시250ML', '40049_코카환타오렌지250ML', '50012_일화맥콜250ML', '60008_일화천연사이다250ML', '60009_롯데펩시콜라250ML', '60037_코카환타파인애플250ML', '90118_코카콜라)스프라이트250ML']\n"
     ]
    }
   ],
   "source": [
    "print('학습 데이터셋 크기:', len(train_datasets))\n",
    "print('테스트 데이터셋 크기:', len(test_datasets))\n",
    "\n",
    "class_names = train_datasets.classes\n",
    "print('클래스:', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "656f1288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.55 20.   30.   40.   50.  ]\n",
      " [ 0.5   1.   11.   11.   20.  ]]\n"
     ]
    }
   ],
   "source": [
    "#anchor\n",
    "\n",
    "import numpy as np\n",
    "#from config import INPUT_SIZE\n",
    "\n",
    "_default_anchors_setting = (#3부분?!!\n",
    "    dict(layer='p3', stride=32, size=48, scale=[2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
    "    dict(layer='p4', stride=64, size=96, scale=[2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
    "    dict(layer='p5', stride=128, size=192, scale=[1, 2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
    ")\n",
    "\n",
    "\n",
    "def generate_default_anchor_maps(anchors_setting=None, input_shape=INPUT_SIZE):\n",
    "    \"\"\"\n",
    "    generate default anchor\n",
    "    :param anchors_setting: all informations of anchors\n",
    "    :param input_shape: shape of input images, e.g. (h, w)\n",
    "    :return: center_anchors: # anchors * 4 (oy, ox, h, w)\n",
    "             edge_anchors: # anchors * 4 (y0, x0, y1, x1)\n",
    "             anchor_area: # anchors * 1 (area)\n",
    "    \"\"\"\n",
    "    if anchors_setting is None:\n",
    "        anchors_setting = _default_anchors_setting\n",
    "\n",
    "    center_anchors = np.zeros((0, 4), dtype=np.float32)\n",
    "    edge_anchors = np.zeros((0, 4), dtype=np.float32)\n",
    "    anchor_areas = np.zeros((0,), dtype=np.float32)\n",
    "    input_shape = np.array(input_shape, dtype=int)\n",
    "\n",
    "    for anchor_info in anchors_setting:\n",
    "\n",
    "        stride = anchor_info['stride']\n",
    "        size = anchor_info['size']\n",
    "        scales = anchor_info['scale']\n",
    "        aspect_ratios = anchor_info['aspect_ratio']\n",
    "\n",
    "        output_map_shape = np.ceil(input_shape.astype(np.float32) / stride) #np.ceil:소수점 올림!!->정수\n",
    "        output_map_shape = output_map_shape.astype(np.int)\n",
    "        output_shape = tuple(output_map_shape) + (4,)\n",
    "        ostart = stride / 2.\n",
    "        oy = np.arange(ostart, ostart + stride * output_shape[0], stride)\n",
    "        oy = oy.reshape(output_shape[0], 1)\n",
    "        ox = np.arange(ostart, ostart + stride * output_shape[1], stride)\n",
    "        ox = ox.reshape(1, output_shape[1])\n",
    "        center_anchor_map_template = np.zeros(output_shape, dtype=np.float32)\n",
    "        center_anchor_map_template[:, :, 0] = oy\n",
    "        center_anchor_map_template[:, :, 1] = ox\n",
    "        for scale in scales:\n",
    "            for aspect_ratio in aspect_ratios:\n",
    "                center_anchor_map = center_anchor_map_template.copy()\n",
    "                center_anchor_map[:, :, 2] = size * scale / float(aspect_ratio) ** 0.5\n",
    "                center_anchor_map[:, :, 3] = size * scale * float(aspect_ratio) ** 0.5\n",
    "\n",
    "                edge_anchor_map = np.concatenate((center_anchor_map[..., :2] - center_anchor_map[..., 2:4] / 2.,\n",
    "                                                  center_anchor_map[..., :2] + center_anchor_map[..., 2:4] / 2.),\n",
    "                                                 axis=-1)\n",
    "                anchor_area_map = center_anchor_map[..., 2] * center_anchor_map[..., 3]\n",
    "                center_anchors = np.concatenate((center_anchors, center_anchor_map.reshape(-1, 4)))\n",
    "                edge_anchors = np.concatenate((edge_anchors, edge_anchor_map.reshape(-1, 4)))\n",
    "                anchor_areas = np.concatenate((anchor_areas, anchor_area_map.reshape(-1)))\n",
    "\n",
    "    return center_anchors, edge_anchors, anchor_areas\n",
    "\n",
    "# IoU: https://deep-learning-study.tistory.com/402 \n",
    "# predicted bounding box가 ground-truth bounding box와 얼마나 일치하는지 측정하기 위한 평가 지표를 정의\n",
    "# area of overlap / area of union\n",
    "def hard_nms(cdds, topn=10, iou_thresh=0.25): #non-maximum suppression\n",
    "    #object detector가 예측한 bounding box 중에서 정확한 bounding box를 선택하도록 하는 기법\n",
    "    #iou_thresh:한계점\n",
    "    if not (type(cdds).__module__ == 'numpy' and len(cdds.shape) == 2 and cdds.shape[1] >= 5):\n",
    "        raise TypeError('edge_box_map should be N * 5+ ndarray')\n",
    "\n",
    "    cdds = cdds.copy()\n",
    "    indices = np.argsort(cdds[:, 0])#모든 행 첫번째 열 #np.argsort:numpy array 정렬 #그래서 행이 총 3개면 [0,1,2]임\n",
    "    cdds = cdds[indices]#cdds 그대로 가져옴 ###########이거 왜 필요하죠..? 그냥 cdds인데...\n",
    "    cdd_results = []\n",
    "\n",
    "    res = cdds\n",
    "\n",
    "    while res.any():\n",
    "        cdd = res[-1]# 마지막 행\n",
    "        cdd_results.append(cdd)\n",
    "        if len(cdd_results) == topn:\n",
    "            return np.array(cdd_results)\n",
    "        res = res[:-1] # 마지막 행 제외\n",
    "\n",
    "        start_max = np.maximum(res[:, 1:3], cdd[1:3])# 두 개의 array에 대해 동일한 위치의 성분끼리 비교하여 최대값 또는 최소값 계산\n",
    "        end_min = np.minimum(res[:, 3:5], cdd[3:5])\n",
    "        lengths = end_min - start_max\n",
    "        intersec_map = lengths[:, 0] * lengths[:, 1]\n",
    "        intersec_map[np.logical_or(lengths[:, 0] < 0, lengths[:, 1] < 0)] = 0\n",
    "        iou_map_cur = intersec_map / ((res[:, 3] - res[:, 1]) * (res[:, 4] - res[:, 2]) + (cdd[3] - cdd[1]) * (\n",
    "            cdd[4] - cdd[2]) - intersec_map)\n",
    "        res = res[iou_map_cur < iou_thresh]\n",
    "\n",
    "    return np.array(cdd_results)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    a = hard_nms(np.array([\n",
    "        [0.4, 1, 10, 12, 20],\n",
    "        [0.5, 1, 11, 11, 20],\n",
    "        [0.55, 20, 30, 40, 50]\n",
    "    ]), topn=100, iou_thresh=0.4)\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9768ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'layer': 'p3',\n",
       "  'stride': 32,\n",
       "  'size': 48,\n",
       "  'scale': [1.2599210498948732, 1.5874010519681994],\n",
       "  'aspect_ratio': [0.667, 1, 1.5]},\n",
       " {'layer': 'p4',\n",
       "  'stride': 64,\n",
       "  'size': 96,\n",
       "  'scale': [1.2599210498948732, 1.5874010519681994],\n",
       "  'aspect_ratio': [0.667, 1, 1.5]},\n",
       " {'layer': 'p5',\n",
       "  'stride': 128,\n",
       "  'size': 192,\n",
       "  'scale': [1, 1.2599210498948732, 1.5874010519681994],\n",
       "  'aspect_ratio': [0.667, 1, 1.5]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################\n",
    "\n",
    "_default_anchors_setting = (#3부분?!!\n",
    "    dict(layer='p3', stride=32, size=48, scale=[2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
    "    dict(layer='p4', stride=64, size=96, scale=[2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
    "    dict(layer='p5', stride=128, size=192, scale=[1, 2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
    ")\n",
    "_default_anchors_setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d8f767f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], shape=(0, 4), dtype=float32),\n",
       " array([], shape=(0, 4), dtype=float32),\n",
       " array([], dtype=float32),\n",
       " array([224, 224]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################\n",
    "INPUT_SIZE = (224, 224)\n",
    "input_shape=INPUT_SIZE\n",
    "\n",
    "center_anchors = np.zeros((0, 4), dtype=np.float32)\n",
    "edge_anchors = np.zeros((0, 4), dtype=np.float32)\n",
    "anchor_areas = np.zeros((0,), dtype=np.float32)\n",
    "input_shape = np.array(input_shape, dtype=int)\n",
    "\n",
    "center_anchors, edge_anchors, anchor_areas,input_shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "624319be",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "stride = 32\n",
    "size = 48\n",
    "scales = [1.2599210498948732, 1.5874010519681994]\n",
    "aspect_ratios = [0.667, 1, 1.5]\n",
    "\n",
    "output_map_shape = np.ceil(input_shape.astype(np.float32) / stride) #np.ceil:소수점 올림!!->정수\n",
    "output_map_shape = output_map_shape.astype(np.int)\n",
    "output_shape = tuple(output_map_shape) + (4,)\n",
    "ostart = stride / 2.\n",
    "oy = np.arange(ostart, ostart + stride * output_shape[0], stride)\n",
    "oy = oy.reshape(output_shape[0], 1)\n",
    "ox = np.arange(ostart, ostart + stride * output_shape[1], stride)\n",
    "ox = ox.reshape(1, output_shape[1])\n",
    "center_anchor_map_template = np.zeros(output_shape, dtype=np.float32)\n",
    "center_anchor_map_template[:, :, 0] = oy\n",
    "center_anchor_map_template[:, :, 1] = ox\n",
    "for scale in scales:\n",
    "    for aspect_ratio in aspect_ratios:\n",
    "        center_anchor_map = center_anchor_map_template.copy()\n",
    "        center_anchor_map[:, :, 2] = size * scale / float(aspect_ratio) ** 0.5\n",
    "        center_anchor_map[:, :, 3] = size * scale * float(aspect_ratio) ** 0.5\n",
    "\n",
    "        edge_anchor_map = np.concatenate((center_anchor_map[..., :2] - center_anchor_map[..., 2:4] / 2.,\n",
    "                                          center_anchor_map[..., :2] + center_anchor_map[..., 2:4] / 2.),\n",
    "                                         axis=-1)\n",
    "        anchor_area_map = center_anchor_map[..., 2] * center_anchor_map[..., 3]\n",
    "        center_anchors = np.concatenate((center_anchors, center_anchor_map.reshape(-1, 4)))\n",
    "        edge_anchors = np.concatenate((edge_anchors, edge_anchor_map.reshape(-1, 4)))\n",
    "        anchor_areas = np.concatenate((anchor_areas, anchor_area_map.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f1adc7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7, 7]),\n",
       " (7, 7, 4),\n",
       " array([[ 16.],\n",
       "        [ 48.],\n",
       "        [ 80.],\n",
       "        [112.],\n",
       "        [144.],\n",
       "        [176.],\n",
       "        [208.]]),\n",
       " array([[ 16.,  48.,  80., 112., 144., 176., 208.]]),\n",
       " array([[[ 16.,  16.,   0.,   0.],\n",
       "         [ 16.,  48.,   0.,   0.],\n",
       "         [ 16.,  80.,   0.,   0.],\n",
       "         [ 16., 112.,   0.,   0.],\n",
       "         [ 16., 144.,   0.,   0.],\n",
       "         [ 16., 176.,   0.,   0.],\n",
       "         [ 16., 208.,   0.,   0.]],\n",
       " \n",
       "        [[ 48.,  16.,   0.,   0.],\n",
       "         [ 48.,  48.,   0.,   0.],\n",
       "         [ 48.,  80.,   0.,   0.],\n",
       "         [ 48., 112.,   0.,   0.],\n",
       "         [ 48., 144.,   0.,   0.],\n",
       "         [ 48., 176.,   0.,   0.],\n",
       "         [ 48., 208.,   0.,   0.]],\n",
       " \n",
       "        [[ 80.,  16.,   0.,   0.],\n",
       "         [ 80.,  48.,   0.,   0.],\n",
       "         [ 80.,  80.,   0.,   0.],\n",
       "         [ 80., 112.,   0.,   0.],\n",
       "         [ 80., 144.,   0.,   0.],\n",
       "         [ 80., 176.,   0.,   0.],\n",
       "         [ 80., 208.,   0.,   0.]],\n",
       " \n",
       "        [[112.,  16.,   0.,   0.],\n",
       "         [112.,  48.,   0.,   0.],\n",
       "         [112.,  80.,   0.,   0.],\n",
       "         [112., 112.,   0.,   0.],\n",
       "         [112., 144.,   0.,   0.],\n",
       "         [112., 176.,   0.,   0.],\n",
       "         [112., 208.,   0.,   0.]],\n",
       " \n",
       "        [[144.,  16.,   0.,   0.],\n",
       "         [144.,  48.,   0.,   0.],\n",
       "         [144.,  80.,   0.,   0.],\n",
       "         [144., 112.,   0.,   0.],\n",
       "         [144., 144.,   0.,   0.],\n",
       "         [144., 176.,   0.,   0.],\n",
       "         [144., 208.,   0.,   0.]],\n",
       " \n",
       "        [[176.,  16.,   0.,   0.],\n",
       "         [176.,  48.,   0.,   0.],\n",
       "         [176.,  80.,   0.,   0.],\n",
       "         [176., 112.,   0.,   0.],\n",
       "         [176., 144.,   0.,   0.],\n",
       "         [176., 176.,   0.,   0.],\n",
       "         [176., 208.,   0.,   0.]],\n",
       " \n",
       "        [[208.,  16.,   0.,   0.],\n",
       "         [208.,  48.,   0.,   0.],\n",
       "         [208.,  80.,   0.,   0.],\n",
       "         [208., 112.,   0.,   0.],\n",
       "         [208., 144.,   0.,   0.],\n",
       "         [208., 176.,   0.,   0.],\n",
       "         [208., 208.,   0.,   0.]]], dtype=float32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_map_shape,output_shape,oy,ox, center_anchor_map_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "121f2ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((294, 4), (294, 4), (294,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_anchors.shape, edge_anchors.shape, anchor_areas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8757ac19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 16.      ,  16.      ,  74.049416,  49.39096 ],\n",
       "        [ 16.      ,  48.      ,  74.049416,  49.39096 ],\n",
       "        [ 16.      ,  80.      ,  74.049416,  49.39096 ],\n",
       "        ...,\n",
       "        [208.      , 144.      ,  62.21316 ,  93.31974 ],\n",
       "        [208.      , 176.      ,  62.21316 ,  93.31974 ],\n",
       "        [208.      , 208.      ,  62.21316 ,  93.31974 ]], dtype=float32),\n",
       " array([[-21.024708,  -8.69548 ,  53.024708,  40.69548 ],\n",
       "        [-21.024708,  23.30452 ,  53.024708,  72.69548 ],\n",
       "        [-21.024708,  55.30452 ,  53.024708, 104.69548 ],\n",
       "        ...,\n",
       "        [176.89342 ,  97.34013 , 239.10658 , 190.65987 ],\n",
       "        [176.89342 , 129.34013 , 239.10658 , 222.65987 ],\n",
       "        [176.89342 , 161.34013 , 239.10658 , 254.65987 ]], dtype=float32),\n",
       " array([3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718,\n",
       "        3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718,\n",
       "        3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718,\n",
       "        3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718,\n",
       "        3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718,\n",
       "        3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718,\n",
       "        3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718,\n",
       "        3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718, 3657.3718,\n",
       "        3657.3718, 3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 ,\n",
       "        3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 ,\n",
       "        3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 ,\n",
       "        3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 ,\n",
       "        3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 ,\n",
       "        3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 ,\n",
       "        3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 ,\n",
       "        3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 , 3657.372 ,\n",
       "        3657.372 , 3657.372 , 3657.3723, 3657.3723, 3657.3723, 3657.3723,\n",
       "        3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723,\n",
       "        3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723,\n",
       "        3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723,\n",
       "        3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723,\n",
       "        3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723,\n",
       "        3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723,\n",
       "        3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723, 3657.3723,\n",
       "        3657.3723, 3657.3723, 3657.3723, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163,\n",
       "        5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163, 5805.7163],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_anchors, edge_anchors, anchor_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f7720b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e10d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://deep-learning-study.tistory.com/403\n",
    "## hard-nms,soft-nms 차이\n",
    "## ^ https://eehoeskrap.tistory.com/407\n",
    "\n",
    "import torch\n",
    "\n",
    "from IoU import intersection_over_union\n",
    "\n",
    "def nms(bboxes, iou_threshold, threshold, box_format='corners'):\n",
    "\n",
    "    # bboxes가 list인지 확인합니다.\n",
    "    assert type(bboxes) == list #뒤의 조건이 True가 아니면 assertError 나옴\n",
    "\n",
    "    # box 점수가 threshold보다 높은 것을 선별합니다.\n",
    "    # box shape는 [class, score, x1, y1, x2, y2] 입니다.\n",
    "    bboxes = [box for box in bboxes if box[1] > threshold]\n",
    "    # 점수 오름차순으로 정렬합니다.\n",
    "    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n",
    "    bboxes_after_nmn = []\n",
    "\n",
    "    # bboxes가 모두 제거될때 까지 반복합니다.\n",
    "    while bboxes:\n",
    "        # 0번째 index가 가장 높은 점수를 갖고있는 box입니다. 이것을 선택하고 bboxes에서 제거합니다.\n",
    "        chosen_box = bboxes.pop(0)\n",
    "\n",
    "        # box가 선택된 box와의 iou가 임계치보다 낮거나\n",
    "        # class가 다르다면 bboxes에 남기고, 그 이외는 다 없앱니다.\n",
    "        bboxes = [box for box in bboxes if box[0] != chosen_box[0] \\\n",
    "               or intersection_over_union(torch.tensor(chosen_box[2:]),\n",
    "                                          torch.tensor(box[2:]),\n",
    "                                          box_format=box_format)\n",
    "                    < iou_threshold]\n",
    "\n",
    "        # 선택된 박스를 추가합니다.\n",
    "        bboxes_after_nmn.append(chosen_box)\n",
    "\n",
    "    return bboxes_after_nmn\n",
    "\n",
    "\n",
    "# IoU: https://deep-learning-study.tistory.com/402 \n",
    "# predicted bounding box가 ground-truth bounding box와 얼마나 일치하는지 측정하기 위한 평가 지표를 정의\n",
    "# area of overlap / area of union\n",
    "def hard_nms(cdds, topn=10, iou_thresh=0.25): #non-maximum suppression\n",
    "    #iou_thresh:한계점\n",
    "    if not (type(cdds).__module__ == 'numpy' and len(cdds.shape) == 2 and cdds.shape[1] >= 5):\n",
    "        raise TypeError('edge_box_map should be N * 5+ ndarray')\n",
    "\n",
    "    cdds = cdds.copy()\n",
    "    indices = np.argsort(cdds[:, 0])#모든 행 첫번째 열 #np.argsort:numpy array 정렬 #그래서 행이 총 3개면 [0,1,2]임\n",
    "    cdds = cdds[indices] #cdds 그대로 가져옴 ###########이거 왜 필요하죠..? 그냥 cdds인데...\n",
    "    cdd_results = []\n",
    "\n",
    "    res = cdds\n",
    "\n",
    "    while res.any():\n",
    "        cdd = res[-1] #마지막 행\n",
    "        cdd_results.append(cdd)\n",
    "        if len(cdd_results) == topn:\n",
    "            return np.array(cdd_results)\n",
    "        res = res[:-1] #마지막 행 제외 \n",
    "\n",
    "        start_max = np.maximum(res[:, 1:3], cdd[1:3])# 두 개의 array에 대해 동일한 위치의 성분끼리 비교하여 최대값 또는 최소값 계산\n",
    "        end_min = np.minimum(res[:, 3:5], cdd[3:5])\n",
    "        lengths = end_min - start_max\n",
    "        intersec_map = lengths[:, 0] * lengths[:, 1]\n",
    "        intersec_map[np.logical_or(lengths[:, 0] < 0, lengths[:, 1] < 0)] = 0\n",
    "        iou_map_cur = intersec_map / ((res[:, 3] - res[:, 1]) * (res[:, 4] - res[:, 2]) + (cdd[3] - cdd[1]) * (\n",
    "            cdd[4] - cdd[2]) - intersec_map)\n",
    "        res = res[iou_map_cur < iou_thresh]\n",
    "\n",
    "    return np.array(cdd_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af1123fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.array([\n",
    "        [0.4, 0, 10, 12, 20],\n",
    "        [0.5, 1, 11, 11, 20],\n",
    "#        [0.55, 20, 30, 40, 50]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4d89838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 0.5])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ffcbaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices=np.argsort(c[:,0])#[0,1,2]\n",
    "np.argsort(c[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "530a3fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4,  0. , 10. , 12. , 20. ],\n",
       "       [ 0.5,  1. , 11. , 11. , 20. ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7e6e624e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4,  0. , 10. , 12. , 20. ],\n",
       "       [ 0.5,  1. , 11. , 11. , 20. ]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c[[0,1,2]]\n",
    "c[[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2e579999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  1. , 11. , 11. , 20. ])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdd=c[-1]\n",
    "cdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6d2d3e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "393fafc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4,  0. , 10. , 12. , 20. ]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=c[:-1]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3e47069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 11.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_max=np.maximum(res[:, 1:3], cdd[1:3])\n",
    "start_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cfc7f577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 10.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6c96b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., 11.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdd[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4668eb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 20.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_min=np.minimum(res[:, 3:5], cdd[3:5])\n",
    "end_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2f603fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.,  9.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = end_min - start_max\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "570344c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersec_map = lengths[:, 0] * lengths[:, 1]\n",
    "intersec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d23b96b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersec_map[np.logical_or(lengths[:, 0] < 0, lengths[:, 1] < 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d3bd069d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logical_or(lengths[:, 0] < 0, lengths[:, 1] < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "df16f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersec_map[np.logical_or(lengths[:, 0] < 0, lengths[:, 1] < 0)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "760dedfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "548d680d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_map_cur = intersec_map / ((res[:, 3] - res[:, 1]) * (res[:, 4] - res[:, 2]) + (cdd[3] - cdd[1]) * (\n",
    "            cdd[4] - cdd[2]) - intersec_map)\n",
    "iou_map_cur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "04cdef66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 5), dtype=float64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[iou_map_cur < 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563107a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d97fcb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet\n",
    "\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample# downsampling:차원을 줄여서 적은 메모리로 깊은 convolution을 할 수 있게 한다. \n",
    "        # 보통 stride를 2 이상으로 하는 convolution을 사용하거나 pooling을 사용한다. \n",
    "        # 이 과정을 거치면 어쩔 수 없이 feature의 정보를 잃게된다.\n",
    "        # https://m.blog.naver.com/9709193/221979612209\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    # 1x1-> 3x3 -> 1x1\n",
    "    \n",
    "    # Convolution Parameters = Kernel Size x Kernel Size x Input Channel x Output Channel\n",
    "    #1x1 Convolution: 연산량이 작기 때문에 Feature Map(Output Channel)을 줄이거나 키울 때 사용\n",
    "    #차원, 채널 축소 후 공간적 특성 추출(3x3 Convolution이 연산량이 9배 많기 때문에), 채널 증가, parameters 감소\n",
    "\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)# If True, adds a learnable bias to the output.\n",
    "        ## BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정합니다.\n",
    "        ## https://deep-learning-study.tistory.com/534\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        feature1 = x\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = nn.Dropout(p=0.5)(x)\n",
    "        feature2 = x\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x, feature1, feature2\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43298229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
